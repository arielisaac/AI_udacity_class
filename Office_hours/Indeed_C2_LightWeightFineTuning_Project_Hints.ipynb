{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS0aUejsau1h"
      },
      "source": [
        "# Lightweight Fine-Tuning Project (Hints)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KR-eMsKa7NL"
      },
      "source": [
        "TODO: In this cell, describe your choices for each of the following\n",
        "\n",
        "* PEFT technique: DoRA (Weight-Decomposed Low-Rank Adaptation)\n",
        "* Model: distilbert-base-uncased\n",
        "* Evaluation approach: Accuracy\n",
        "* Fine-tuning dataset: sms_spam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAFDyH9Ea_ox"
      },
      "source": [
        "## Loading and Evaluating a Foundation Model\n",
        "\n",
        "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVXgHeK78zJF"
      },
      "outputs": [],
      "source": [
        "# Installing required libraries\n",
        "# Note: After running this cell, restart the kernel to ensure the new packages are properly loaded.\n",
        "# Instructions to restart the kernel:\n",
        "# 1. Go to the top menu in Jupyter Notebook and click on \"Kernel\".\n",
        "# 2. From the dropdown, select \"Restart\".\n",
        "# 3. Confirm the restart when prompted.\n",
        "# 4. Wait for the kernel to restart (indicated by the kernel icon becoming active again).\n",
        "# 5. Once the kernel is restarted, continue executing cells from the next one onwards.\n",
        "\n",
        "!pip install -q -U transformers\n",
        "!pip install -q -U accelerate\n",
        "!pip install -q -U datasets\n",
        "!pip install -q -U peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJqxvORi9B-X"
      },
      "outputs": [],
      "source": [
        "# Suppressing unrelated warnings\n",
        "import torchvision\n",
        "torchvision.disable_beta_transforms_warning()\n",
        "\n",
        "# Necessary imports\n",
        "from datasets import load_dataset\n",
        "from peft import (AutoPeftModelForSequenceClassification,\n",
        "                  LoraConfig,\n",
        "                  get_peft_model,\n",
        "                  TaskType)\n",
        "from transformers import (AutoTokenizer,\n",
        "                          AutoModelForSequenceClassification,\n",
        "                          DataCollatorWithPadding,\n",
        "                          Trainer,\n",
        "                          TrainingArguments)\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWTZTkR-9LgD"
      },
      "outputs": [],
      "source": [
        "# Loading the sms_spam dataset\n",
        "# Dataset here: https://huggingface.co/datasets/sms_spam\n",
        "# The sms_spam dataset only has a train split, so we use the train_test_split method to split it into train and test\n",
        "dataset = load_dataset(\"sms_spam\", split=\"train\").train_test_split(\n",
        "    test_size=0.2, shuffle=True, seed=23\n",
        ")\n",
        "\n",
        "splits = [\"train\", \"test\"]\n",
        "\n",
        "# View the dataset characteristics\n",
        "dataset[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j77qHzGX9aRY"
      },
      "outputs": [],
      "source": [
        "# TODO: Load the tokenizer for the \"distilbert-base-uncased\" model.\n",
        "# Hint 1: Use AutoTokenizer.from_pretrained(\"<model-name>\").\n",
        "# Hint 2: The tokenizer will help convert text to tokens that the model can process.\n",
        "tokenizer = None  # Replace None with the appropriate code.\n",
        "\n",
        "# TODO: Tokenize the dataset using the loaded tokenizer.\n",
        "# Hint 1: Use the map() function with a lambda to apply tokenization to the \"sms\" column.\n",
        "# Hint 2: Set truncation=True to ensure the sequences fit within the model's maximum input length.\n",
        "tokenized_dataset = {}\n",
        "for split in splits:\n",
        "    tokenized_dataset[split] = None  # Replace None with the appropriate code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v9Pepou9bol"
      },
      "source": [
        "<details>\n",
        "<summary>Click to see the answer</summary>\n",
        "\n",
        "### Solution for Tokenizer Initialization and Tokenization\n",
        "```python\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "tokenized_dataset = {}\n",
        "for split in splits:\n",
        "    tokenized_dataset[split] = dataset[split].map(\n",
        "        lambda x: tokenizer(x[\"sms\"], truncation=True), batched=True\n",
        "    )\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh2b6N6G9f7l"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement a function to compute accuracy from predictions and labels.\n",
        "# Hint 1: Use np.argmax to find the predicted class from the logits.\n",
        "# Hint 2: Compare the predicted classes with the true labels to calculate accuracy.\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = None  # Replace None with np.argmax to get predicted classes.\n",
        "    return {\"accuracy\": None}  # Replace None to compute the mean of correct predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84tNWN1b9s0E"
      },
      "source": [
        "<details>\n",
        "<summary>Click to see the answer</summary>\n",
        "\n",
        "### Solution for Metrics Function\n",
        "```python\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return {\"accuracy\": (predictions == labels).mean()}\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEUcg9F09toX"
      },
      "outputs": [],
      "source": [
        "# Loading distilbert-base-uncased for sequence classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=2,\n",
        "    id2label={0: \"not spam\", 1: \"spam\"},\n",
        "    label2id={\"not spam\": 0, \"spam\": 1},\n",
        ")\n",
        "\n",
        "# Define a function to print the trainable parameters of the model\n",
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n",
        "print()\n",
        "print(print_number_of_trainable_model_parameters(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx_JPg11-CEB"
      },
      "outputs": [],
      "source": [
        "# TODO: Create the Trainer class instance to evaluate the pre-trained model on the test set.\n",
        "# Hint 1: Trainer's eval_dataset argument takes an evaluation dataset (i.e. tokenized_dataset[\"test\"]) and computes_metrics argument will take the compute_metrics function callable defined above.\n",
        "# Hint 2: args argument of Trainer will be this --> args=TrainingArguments(output_dir=\"./result-distilbert-base\", per_device_eval_batch_size=4, report_to=\"none\")\n",
        "print(\"Evaluating the model before fine-tuning...\")\n",
        "trainer = None  # Replace with the code given in Hint 2 above\n",
        "pre_finetune_eval = None  # Replace None with the appropriate trainer.evaluate() call.\n",
        "print(pre_finetune_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO3T98c5-G8a"
      },
      "source": [
        "<details>\n",
        "<summary>Click to see the answer</summary>\n",
        "\n",
        "### Solution for Model Evaluation Before Fine-Tuning\n",
        "```python\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=TrainingArguments(\n",
        "        output_dir=\"./result-distilbert-base\",\n",
        "        per_device_eval_batch_size=4,\n",
        "        report_to=\"none\"\n",
        "    ),\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "pre_finetune_eval = trainer.evaluate()\n",
        "print(pre_finetune_eval)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nScvRlTUbHqm"
      },
      "source": [
        "## Performing Parameter-Efficient Fine-Tuning\n",
        "\n",
        "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbVGrvQN-HoH"
      },
      "outputs": [],
      "source": [
        "# TODO: Complete the LoRA configuration.\n",
        "# Hint 1: Use r=16, lora_alpha=16, and lora_dropout=0.05 as default values.\n",
        "# Hint 2: Specify target_modules where LoRA is applied (e.g., MultiHeadAttention layers) i.e. target_modules=[\"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\"]\n",
        "# Hint 3: Specify modules_to_save i.e. modules where full fine-tuning is done; for e.g. modules_to_save=[\"classifier\"]\n",
        "# Hint 4: Use use_dora=True\n",
        "# Hint 5: Use task_type=TaskType.SEQ_CLS for sequence classification tasks.\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=None,  # Replace None with the list of target modules i.e. modules targeted for Parameter Efficient Fine-Tuning.\n",
        "    modules_to_save=None, # Replace None with the list of modules for which full fine-tuning will be done.\n",
        "    bias='none',\n",
        "    task_type=None  # Replace None with the correct task type.\n",
        ")\n",
        "\n",
        "# Get PEFT model\n",
        "peft_model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Reduced trainable parameters\n",
        "print(print_number_of_trainable_model_parameters(peft_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY8HRnB6_ASP"
      },
      "source": [
        "<details>\n",
        "<summary>Click to see the answer</summary>\n",
        "\n",
        "### Solution for LoRA Configuration\n",
        "```python\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\"],\n",
        "    modules_to_save=[\"classifier\"],\n",
        "    bias='none',\n",
        "    use_dora=True,\n",
        "    task_type=TaskType.SEQ_CLS\n",
        ")\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sq2sm5DC_GYI"
      },
      "outputs": [],
      "source": [
        "# Training and evaluating the model prepared for PEFT\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=TrainingArguments(\n",
        "        output_dir=\"./result-distilbert-lora\",\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        save_strategy=\"epoch\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_steps=1,\n",
        "        num_train_epochs=2,\n",
        "        weight_decay=0.01,\n",
        "        load_best_model_at_end=True,\n",
        "        report_to=\"none\"\n",
        "    ),\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lTVwryM_XzI"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model after fine-tuning\n",
        "print(\"Evaluating the model after fine-tuning...\")\n",
        "post_finetune_eval = trainer.evaluate()\n",
        "print(post_finetune_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzywX_xD_pVn"
      },
      "outputs": [],
      "source": [
        "# TODO: Save the fine-tuned model to a directory.\n",
        "# Hint: Use model.save_pretrained(\"<directory-name>\").\n",
        "peft_model.save_pretrained(None)  # Replace None with the directory path."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQZCfbX0_s3H"
      },
      "source": [
        "<details>\n",
        "<summary>Click to see the answer</summary>\n",
        "\n",
        "### Solution for Saving the Model\n",
        "```python\n",
        "peft_model.save_pretrained(\"distilbert-lora\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aL2hum9bY3G"
      },
      "source": [
        "## Performing Inference with a PEFT Model\n",
        "\n",
        "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl7A8f6C_wUv"
      },
      "outputs": [],
      "source": [
        "# TODO: Load the saved model from the directory.\n",
        "# Hint: Use AutoPeftModelForSequenceClassification.from_pretrained(\"<directory-name>\").\n",
        "lora_model = None  # Replace None with the appropriate code to load the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAdylTntACmB"
      },
      "source": [
        "<details>\n",
        "<summary>Click to see the answer</summary>\n",
        "\n",
        "### Solution for Loading the Model\n",
        "```python\n",
        "lora_model = AutoPeftModelForSequenceClassification.from_pretrained(\"distilbert-lora\")\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6fe3q2rADSN"
      },
      "outputs": [],
      "source": [
        "# Evaluate the loaded fine-tuned model\n",
        "loaded_trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=TrainingArguments(\n",
        "        output_dir=\"./result-distilbert-lora\",\n",
        "        per_device_eval_batch_size=4,\n",
        "        report_to=\"none\"\n",
        "    ),\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"Evaluating the loaded fine-tuned model...\")\n",
        "loaded_model_eval = loaded_trainer.evaluate()\n",
        "print(loaded_model_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4m0AzDyuFXc1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}