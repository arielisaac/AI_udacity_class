{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arielisaac/AI_udacity_class/blob/main/project_1/LightweightFineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f35354cd",
      "metadata": {
        "id": "f35354cd"
      },
      "source": [
        "# Lightweight Fine-Tuning Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "560fb3ff",
      "metadata": {
        "id": "560fb3ff"
      },
      "source": [
        "TODO: In this cell, describe your choices for each of the following\n",
        "\n",
        "* PEFT technique:\n",
        "* Model:\n",
        "* Evaluation approach:\n",
        "* Fine-tuning dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de8d76bb",
      "metadata": {
        "id": "de8d76bb"
      },
      "source": [
        "## Loading and Evaluating a Foundation Model\n",
        "\n",
        "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
      ]
    },
    {
      "cell_type": "code",
      "id": "f551c63a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-22T18:25:45.388236Z",
          "start_time": "2025-04-22T18:25:40.779654Z"
        },
        "id": "f551c63a"
      },
      "source": [
        "!pip install transformers datasets peft accelerate optuna -U -q\n"
      ],
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A few Configurations"
      ],
      "metadata": {
        "id": "WEr2i7xnc3cA"
      },
      "id": "WEr2i7xnc3cA"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Disable torch.compile for stability\n",
        "torch._dynamo.config.disable = True\n",
        "\n",
        "# This is to improve performance on M1 Macs\n",
        "def get_best_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\")\n",
        "    else:\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "device = get_best_device()\n",
        "\n",
        "# ModernBERT blog: https://www.answer.ai/posts/2024-12-19-modernbert.html\n",
        "# Philipp Schmid's blog on Fine-Tuning open LLMs: https://www.philschmid.de/fine-tune-llms-in-2025\n",
        "\n",
        "# https://learn.udacity.com/nanodegrees/nd101-ent-ai-swe-indeed/parts/cd13303/lessons/786df5de-95ad-4e0d-be51-cc8a1c1e40fe/concepts/ed4cd691-b999-454e-b715-a603fb2aeeb5?lesson_tab=lesson\n",
        "from peft import LoraConfig\n",
        "config = LoraConfig()\n",
        "# https://huggingface.co/docs/peft/main/en/conceptual_guides/lora"
      ],
      "metadata": {
        "id": "6A2Q-abqUJUq"
      },
      "id": "6A2Q-abqUJUq",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Dataset"
      ],
      "metadata": {
        "id": "8ds_cnNrc_5N"
      },
      "id": "8ds_cnNrc_5N"
    },
    {
      "cell_type": "code",
      "id": "4935cb4d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-27T02:33:23.991633Z",
          "start_time": "2025-04-27T02:33:16.503879Z"
        },
        "id": "4935cb4d",
        "outputId": "0ea94f35-2e97-4f55-f85c-ba415ba7863b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# # Another dataset availabe: sms_spam\n",
        "# sms_spam_dataset = load_dataset(\"sms_spam\", split=[\"train\"])[0]\n",
        "# print(sms_spam_dataset)\n",
        "# # Split the dataset into train and test sets (assuming `dataset` is a Hugging Face Dataset object)\n",
        "# sms_spam_dataset_train_test_split = sms_spam_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "# test_dataset = sms_spam_dataset_train_test_split['test']\n",
        "# print(sms_spam_dataset[:5])\n",
        "# \"\"\"\n",
        "# Convert the dataset to a pandas DataFrame\n",
        "# \"\"\"\n",
        "# import pandas as pd\n",
        "\n",
        "# # Convert the entire dataset to a pandas DataFrame\n",
        "# df = pd.DataFrame(sms_spam_dataset)\n",
        "# # Display the first 10 rows\n",
        "# print(df.head(10))\n",
        "\n",
        "# # Or for more detailed information\n",
        "# display(df.head(10))  # Works in Jupyter notebooks\n",
        "# display(df.describe())  # Works in Jupyter notebooks\n",
        "\n",
        "# for entry in dataset.select(range(3)):\n",
        "#     sms = entry[\"sms\"]\n",
        "#     label = entry[\"label\"]\n",
        "#     print(f\"label={label}, sms={sms}\")\n",
        "\n",
        "\n",
        "# Load the train and test splits of the imdb dataset\n",
        "splits = [\"train\", \"test\"]\n",
        "ds_imdb = {split: ds for split, ds in zip(splits, load_dataset(\"imdb\", split=splits))}\n",
        "\n",
        "\n",
        "# Thin out the dataset to make it run faster for this example\n",
        "for split in splits:\n",
        "    ds_imdb[split] = ds_imdb[split].shuffle(seed=42).select(range(500))\n",
        "print(ds_imdb)\n",
        "\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 500\n",
            "}), 'test': Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 500\n",
            "})}\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Model and Tokenizing the dataset"
      ],
      "metadata": {
        "id": "XsXaWaafdZDc"
      },
      "id": "XsXaWaafdZDc"
    },
    {
      "cell_type": "code",
      "source": [
        "#Models\n",
        "# Very good documentation  https://huggingface.co/transformers/v4.2.2/training.html\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=2,\n",
        "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},  # For converting predictions to strings\n",
        "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1},\n",
        ")\n",
        "\n",
        "\n",
        "#Tokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    \"\"\"Preprocess the imdb dataset by returning tokenized examples.\"\"\"\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_ds = {}\n",
        "for split in splits:\n",
        "    tokenized_ds[split] = ds_imdb[split].map(preprocess_function, batched=True)\n",
        "\n",
        "tokenized_test = ds_imdb[\"test\"].map(preprocess_function, batched=True)\n",
        "\n",
        "# Check that we tokenized the examples properly\n",
        "assert tokenized_ds[\"train\"][0][\"input_ids\"][:5] == [101, 2045, 2003, 2053, 7189]\n",
        "\n",
        "# Show the first example of the tokenized training set\n",
        "print(tokenized_ds[\"train\"][0][\"input_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1d-4rKodcSV",
        "outputId": "92551535-e443-4baa-d906-f572da3aa8d7"
      },
      "id": "e1d-4rKodcSV",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 2045, 2003, 2053, 7189, 2012, 2035, 2090, 3481, 3771, 1998, 6337, 2099, 2021, 1996, 2755, 2008, 2119, 2024, 2610, 2186, 2055, 6355, 6997, 1012, 6337, 2099, 3504, 15594, 2100, 1010, 3481, 3771, 3504, 4438, 1012, 6337, 2099, 14811, 2024, 3243, 3722, 1012, 3481, 3771, 1005, 1055, 5436, 2024, 2521, 2062, 8552, 1012, 1012, 1012, 3481, 3771, 3504, 2062, 2066, 3539, 8343, 1010, 2065, 2057, 2031, 2000, 3962, 12319, 1012, 1012, 1012, 1996, 2364, 2839, 2003, 5410, 1998, 6881, 2080, 1010, 2021, 2031, 1000, 17936, 6767, 7054, 3401, 1000, 1012, 2111, 2066, 2000, 12826, 1010, 2000, 3648, 1010, 2000, 16157, 1012, 2129, 2055, 2074, 9107, 1029, 6057, 2518, 2205, 1010, 2111, 3015, 3481, 3771, 3504, 2137, 2021, 1010, 2006, 1996, 2060, 2192, 1010, 9177, 2027, 9544, 2137, 2186, 1006, 999, 999, 999, 1007, 1012, 2672, 2009, 1005, 1055, 1996, 2653, 1010, 2030, 1996, 4382, 1010, 2021, 1045, 2228, 2023, 2186, 2003, 2062, 2394, 2084, 2137, 1012, 2011, 1996, 2126, 1010, 1996, 5889, 2024, 2428, 2204, 1998, 6057, 1012, 1996, 3772, 2003, 2025, 23105, 2012, 2035, 1012, 1012, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the pre trained(model no training yet)"
      ],
      "metadata": {
        "id": "GaZhkhrndeML"
      },
      "id": "GaZhkhrndeML"
    },
    {
      "cell_type": "code",
      "id": "f28c4a78",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-27T02:39:43.944553Z",
          "start_time": "2025-04-27T02:38:59.769130Z"
        },
        "id": "f28c4a78"
      },
      "source": [
        "\"\"\"\n",
        "My own version\n",
        "\"\"\"\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(len(tokenized_test)):\n",
        "        inputs = {\n",
        "            \"input_ids\": torch.tensor(tokenized_test[i][\"input_ids\"]).unsqueeze(0),\n",
        "            \"attention_mask\": torch.tensor(tokenized_test[i][\"attention_mask\"]).unsqueeze(0),\n",
        "        }\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predicted_label = torch.argmax(logits, dim=1).item()\n",
        "        predictions.append(predicted_label)\n",
        "        true_labels.append(tokenized_test[i][\"label\"])\n",
        "\n",
        "# Evaluate the predictions\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "f1_result = f1_score(true_labels, predictions)\n",
        "\n",
        "print()\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1 result: {f1_result}\")\n",
        "\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "# Display the confusion matrix\n",
        "labels = [\"Negative\", \"Positive\"]  # IMDB sentiment labels\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "disp.plot(ax=ax)\n",
        "plt.title(\"Confusion Matrix for IMDB Sentiment Classification\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform Lightweight Fine-Tuning"
      ],
      "metadata": {
        "id": "4eWNSY95jGT-"
      },
      "id": "4eWNSY95jGT-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the PEFT model"
      ],
      "metadata": {
        "id": "mAduGFabjfHC"
      },
      "id": "mAduGFabjfHC"
    },
    {
      "cell_type": "code",
      "id": "019b9f55",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-26T03:29:42.743968Z",
          "start_time": "2025-04-26T03:29:05.865452Z"
        },
        "id": "019b9f55"
      },
      "source": [
        "# These are just tests to see if I can get the model to work\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import torch\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tokenize the test data\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['sms'], padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(len(tokenized_test)):\n",
        "        inputs = {\n",
        "            \"input_ids\": torch.tensor(tokenized_test[i][\"input_ids\"]).unsqueeze(0),\n",
        "            \"attention_mask\": torch.tensor(tokenized_test[i][\"attention_mask\"]).unsqueeze(0),\n",
        "        }\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.last_hidden_state.mean(dim=1)  # Simplified for classification\n",
        "        predicted_label = torch.argmax(logits, dim=1).item()\n",
        "        predictions.append(predicted_label)\n",
        "        true_labels.append(test_dataset[i][\"label\"])\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Evaluate the predictions\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "\n",
        "last_hidden_states = outputs.last_hidden_state\n",
        "print(outputs)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5176b07f",
      "metadata": {
        "id": "5176b07f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4d52a229",
      "metadata": {
        "id": "4d52a229"
      },
      "source": [
        "## Performing Parameter-Efficient Fine-Tuning\n",
        "\n",
        "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5775fadf",
      "metadata": {
        "id": "5775fadf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "894046c0",
      "metadata": {
        "id": "894046c0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4d4c908",
      "metadata": {
        "id": "c4d4c908"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b47abf88",
      "metadata": {
        "id": "b47abf88"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a7e8a663",
      "metadata": {
        "id": "a7e8a663"
      },
      "source": [
        "###  ⚠️ IMPORTANT ⚠️\n",
        "\n",
        "Due to workspace storage constraints, you should not store the model weights in the same directory but rather use `/tmp` to avoid workspace crashes which are irrecoverable.\n",
        "Ensure you save it in /tmp always."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa7fe003",
      "metadata": {
        "id": "fa7fe003"
      },
      "outputs": [],
      "source": [
        "# Saving the model\n",
        "model.save(\"/tmp/your_model_name\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "615b12c6",
      "metadata": {
        "id": "615b12c6"
      },
      "source": [
        "## Performing Inference with a PEFT Model\n",
        "\n",
        "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "863ec66e",
      "metadata": {
        "id": "863ec66e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc3a8147",
      "metadata": {
        "id": "bc3a8147"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc96905a",
      "metadata": {
        "id": "bc96905a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "866ab28c",
      "metadata": {
        "id": "866ab28c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9a32e4e",
      "metadata": {
        "id": "f9a32e4e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}